{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "df = pd.read_csv('adult.data', header = None)\n",
    "X_train_orig = df.drop(df.columns[[14]], axis=1, inplace=False)\n",
    "Y_train_orig = df[[14]]\n",
    "#df\n",
    "#print Y_train_orig\n",
    "#print X_train_orig\n",
    "X_train = pd.get_dummies(X_train_orig)\n",
    "Y_train = pd.get_dummies(Y_train_orig) # get one hot encoding\n",
    "#Y_train\n",
    "#X_train\n",
    "#X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('adult.test', header = None)\n",
    "X_test_orig = df.drop(df.columns[[14]], axis=1, inplace=False)\n",
    "Y_test_orig = df[[14]]\n",
    "X_test = pd.get_dummies(X_test_orig)\n",
    "Y_test = pd.get_dummies(Y_test_orig) # get one hot encoding\n",
    "Y_test\n",
    "X_test\n",
    "X_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    X = tf.placeholder(tf.float32, [n_x, None], name = \"X\")\n",
    "    Y = tf.placeholder(tf.float32, [n_y, None], name = \"Y\")\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(num_features, num_layers):\n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "    num_neurons = []\n",
    "    num_neurons.append(0)\n",
    "    W = []\n",
    "    W.append(0)\n",
    "    b = []\n",
    "    b.append(0)\n",
    "    for i in range(1, num_layers + 1):\n",
    "        if i == num_layers:\n",
    "            num_neurons.append(2)\n",
    "        else:\n",
    "            num_neurons.append(10)\n",
    "        if i == 1:\n",
    "            arg2 = num_features\n",
    "        else:\n",
    "            arg2 = num_neurons[i - 1]\n",
    "        W.append(tf.get_variable(\"W\" + str(i), [num_neurons[i], arg2], \n",
    "                               initializer = tf.contrib.layers.xavier_initializer(seed = 1)))\n",
    "        b.append(tf.get_variable(\"b\" + str(i), [num_neurons[i] , 1], initializer = tf.zeros_initializer()))\n",
    "\n",
    "    parameters = {}\n",
    "    for i in range(1, num_layers + 1):\n",
    "        parameters[\"W\" + str(i)] = W[i]\n",
    "        parameters[\"b\" + str(i)] = b[i]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "{'W1': <tf.Variable 'W1:0' shape=(5, 3) dtype=float32_ref>, 'b4': <tf.Variable 'b4:0' shape=(5, 1) dtype=float32_ref>, 'b5': <tf.Variable 'b5:0' shape=(2, 1) dtype=float32_ref>, 'W5': <tf.Variable 'W5:0' shape=(2, 5) dtype=float32_ref>, 'W4': <tf.Variable 'W4:0' shape=(5, 5) dtype=float32_ref>, 'W3': <tf.Variable 'W3:0' shape=(5, 5) dtype=float32_ref>, 'b1': <tf.Variable 'b1:0' shape=(5, 1) dtype=float32_ref>, 'b2': <tf.Variable 'b2:0' shape=(5, 1) dtype=float32_ref>, 'b3': <tf.Variable 'b3:0' shape=(5, 1) dtype=float32_ref>, 'W2': <tf.Variable 'W2:0' shape=(5, 5) dtype=float32_ref>}\n"
     ]
    }
   ],
   "source": [
    "#tf.reset_default_graph() \n",
    "p = initialize_parameters(3,5)\n",
    "print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, num_layers):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W = []\n",
    "    W.append(0)\n",
    "    b = []\n",
    "    b.append(0)\n",
    "    Z = []\n",
    "    Z.append(0)\n",
    "    A = []\n",
    "    A.append(X)\n",
    "    for i in range(1, num_layers):\n",
    "        W.append(parameters[\"W\" + str(i)])\n",
    "        b.append(parameters[\"b\" + str(i)])\n",
    "        Z.append(tf.add(tf.matmul(W[i], A[i - 1]), b[i]))\n",
    "        A.append(tf.nn.relu(Z[i]))\n",
    "                                        \n",
    "    Z = tf.add(tf.matmul(parameters[\"W\" + str(num_layers)], A[num_layers - 1]), parameters[\"b\" + str(num_layers)])\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001, num_epochs = 1000, print_cost = True, num_layers = 5):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(X_train.shape[0], num_layers)\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z = forward_propagation(X, parameters, num_layers)\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z, Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            _ , epoch_cost = sess.run([optimizer, cost], feed_dict={X: X_train, Y: Y_train})\n",
    "                \n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        # print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 932.746216\n",
      "Cost after epoch 100: 102.746140\n",
      "Cost after epoch 200: 0.583059\n",
      "Cost after epoch 300: 0.559575\n",
      "Cost after epoch 400: 0.549513\n",
      "Cost after epoch 500: 0.536373\n",
      "Cost after epoch 600: 0.530139\n",
      "Cost after epoch 700: 0.529066\n",
      "Cost after epoch 800: 0.528441\n",
      "Cost after epoch 900: 0.527867\n",
      "Cost after epoch 1000: 0.527318\n",
      "Cost after epoch 1100: 0.526745\n",
      "Cost after epoch 1200: 0.526153\n",
      "Cost after epoch 1300: 0.525560\n",
      "Cost after epoch 1400: 0.524933\n",
      "Cost after epoch 1500: 0.525382\n",
      "Cost after epoch 1600: 0.523619\n",
      "Cost after epoch 1700: 0.522934\n",
      "Cost after epoch 1800: 0.522233\n",
      "Cost after epoch 1900: 0.521636\n",
      "Cost after epoch 2000: 0.520805\n",
      "Cost after epoch 2100: 0.520063\n",
      "Cost after epoch 2200: 0.519319\n",
      "Cost after epoch 2300: 0.518571\n",
      "Cost after epoch 2400: 0.517811\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f12267ffdd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "('Train Accuracy:', 0.79429376)\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train.T, Y_train.T, X_test.T, Y_test.T, num_epochs = 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ -3.62896711e-01,  -3.92981082e-01,  -3.50432396e-01,\n",
       "          -1.86641216e-01,   1.25068605e-01,   6.57946467e-02,\n",
       "           3.53324115e-01,  -5.77179790e-02,  -7.23782182e-02,\n",
       "          -4.63488698e-02,  -1.77715600e-01,  -8.20072889e-02,\n",
       "           3.64492953e-01,   2.00779259e-01,   6.94410801e-02,\n",
       "           3.43843997e-01,   1.54298782e-01,  -8.22227001e-02,\n",
       "          -1.74294695e-01,  -2.27560624e-01,   3.97456229e-01,\n",
       "          -2.00143486e-01,   7.38465190e-02,   3.04749012e-01,\n",
       "          -1.16930425e-01,  -7.38252997e-02,  -3.01831424e-01,\n",
       "          -2.48914063e-02,  -2.01725364e-01,  -2.54542947e-01,\n",
       "           1.93253338e-01],\n",
       "        [ -1.03936195e-02,   8.30292702e-05,  -1.42860383e-01,\n",
       "          -7.92998075e-03,   1.11947656e-02,  -2.43710563e-01,\n",
       "           2.35907376e-01,   1.24957442e-01,  -4.52970862e-02,\n",
       "          -3.00078809e-01,  -9.01323259e-02,   3.28528881e-01,\n",
       "          -9.32728052e-02,  -1.49688274e-01,  -2.73389757e-01,\n",
       "          -5.69962561e-02,  -3.09472799e-01,   3.76130402e-01,\n",
       "          -3.02062869e-01,   8.56170058e-03,  -1.51424915e-01,\n",
       "           2.49539912e-02,  -4.02408659e-01,   1.95682466e-01,\n",
       "          -1.69022307e-01,   1.42676532e-01,   1.30600870e-01,\n",
       "           1.62833691e-01,   1.50733352e-01,  -2.05534428e-01,\n",
       "           1.43106937e-01],\n",
       "        [  2.96038479e-01,  -3.28354150e-01,  -3.19136791e-02,\n",
       "          -1.72986850e-01,   2.00054348e-01,  -1.86987013e-01,\n",
       "          -4.45880532e-01,  -1.88197955e-01,  -3.75525445e-01,\n",
       "          -3.65037411e-01,  -2.05072016e-01,   1.82504207e-02,\n",
       "          -1.04554854e-01,  -2.32166365e-01,  -1.27229854e-01,\n",
       "           3.13549161e-01,   1.80642650e-01,  -1.92384243e-01,\n",
       "           3.25433105e-01,   3.23406011e-01,  -3.76962692e-01,\n",
       "          -5.76109858e-03,  -4.06215787e-01,   4.13067564e-02,\n",
       "           1.92641735e-01,   2.63456136e-01,   2.94128358e-01,\n",
       "           2.06558257e-01,   2.39086077e-01,  -2.31287792e-01,\n",
       "          -1.19435601e-01],\n",
       "        [  2.35731155e-01,  -1.38795540e-01,  -2.25760993e-02,\n",
       "           1.40251681e-01,  -2.11317584e-01,   9.99051630e-02,\n",
       "           3.75777096e-01,   7.87695721e-02,  -1.69083878e-01,\n",
       "          -1.66260317e-01,   2.35032290e-01,   3.23742807e-01,\n",
       "           4.42259699e-01,  -6.62823543e-02,   4.70852733e-01,\n",
       "           2.13638052e-01,  -1.36978254e-01,  -7.46566653e-02,\n",
       "           1.69905592e-02,   4.93286997e-01,  -8.06859583e-02,\n",
       "           4.36748505e-01,   2.95820534e-01,   3.28725934e-01,\n",
       "           3.98240000e-01,   2.26344809e-01,   1.01793811e-01,\n",
       "          -1.89191122e-02,   4.62562032e-02,   2.14166567e-01,\n",
       "          -5.01304902e-02],\n",
       "        [ -2.15957761e-02,   8.61584842e-02,  -4.43215072e-02,\n",
       "           2.72626579e-02,  -3.51565093e-01,   1.31751657e-01,\n",
       "          -2.19678879e-02,   2.65152454e-02,  -8.93157125e-02,\n",
       "           3.28022242e-01,   2.81057417e-01,   6.18821383e-03,\n",
       "          -9.92098153e-02,   2.85061002e-02,  -3.72905165e-01,\n",
       "          -3.68587255e-01,   2.26878703e-01,   4.89881039e-02,\n",
       "           2.30216861e-01,  -1.83250591e-01,   3.03758979e-02,\n",
       "           3.64145994e-01,   3.75422716e-01,   3.56526494e-01,\n",
       "          -3.87005806e-02,   1.90868020e-01,  -2.00496033e-01,\n",
       "          -1.01964176e-02,  -6.67386949e-02,  -1.94930375e-01,\n",
       "           3.59441817e-01]], dtype=float32),\n",
       " 'W2': array([[-0.68854809, -0.74562919, -0.66489875, -0.35412681,  0.23730099],\n",
       "        [ 0.12483656,  0.67038536, -0.10951215, -0.13732803, -0.08794081],\n",
       "        [-0.33719164, -0.15559787,  0.61977613,  0.29315904,  0.13175517],\n",
       "        [ 0.65239811,  0.29276133, -0.15600657, -0.33070093, -0.43176591],\n",
       "        [ 0.75412011, -0.37974557,  0.22299558,  0.67714155, -0.22185987]], dtype=float32),\n",
       " 'W3': array([[-0.82297236, -0.89119732, -0.71767741, -0.42326248,  0.37478656],\n",
       "        [ 0.14920831,  0.80126369, -0.20792046, -0.16413838, -0.19626704]], dtype=float32),\n",
       " 'b1': array([[ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [-0.06788255],\n",
       "        [ 0.10794075],\n",
       "        [ 0.        ]], dtype=float32),\n",
       " 'b2': array([[ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [-0.07528659],\n",
       "        [ 0.        ],\n",
       "        [ 0.08645537]], dtype=float32),\n",
       " 'b3': array([[ 0.07974505],\n",
       "        [-0.07974505]], dtype=float32)}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
